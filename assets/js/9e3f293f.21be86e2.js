"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5502],{5142:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>g,frontMatter:()=>o,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"Starter-Projects/starter-projects-agentic-rag","title":"Agentic RAG","description":"Agentic RAG (Retrieval-Augmented Generation) is an intelligent retrieval system that can decide whether and how to retrieve information from a knowledge base as needed. Traditional RAG methods (such as chunkRAG, MiniRAG, LightRAG, and GraphRAG) have limitations as they rely on predefined workflows and struggle to determine if they have acquired sufficient knowledge to answer questions. To make the RAG process more intelligent, we introduce Agentic RAG powered by AutoAgent, implementing intelligent storage, retrieval, and response.","source":"@site/docs/Starter-Projects/starter-projects-agentic-rag.md","sourceDirName":"Starter-Projects","slug":"/starter-projects-agentic-rag","permalink":"/docs/starter-projects-agentic-rag","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Agentic RAG","slug":"/starter-projects-agentic-rag"},"sidebar":"docsSidebar","previous":{"title":"From Natural Language to Agent","permalink":"/docs/starter-projects-nl-to-agent"},"next":{"title":"For Daily Tasks","permalink":"/docs/user-guide-daily-tasks"}}');var i=t(4848),s=t(8453);const o={title:"Agentic RAG",slug:"/starter-projects-agentic-rag"},a="Agentic RAG Implementation in AutoAgent",c={},l=[{value:"System Architecture",id:"system-architecture",level:2},{value:"1. Required Imports",id:"1-required-imports",level:3},{value:"2. Environment Configuration",id:"2-environment-configuration",level:3},{value:"3. RAG Agent Setup",id:"3-rag-agent-setup",level:3},{value:"4. Query Processing Flow",id:"4-query-processing-flow",level:3},{value:"Usage",id:"usage",level:2},{value:"1. Basic Usage",id:"1-basic-usage",level:3},{value:"2. Parameter Description",id:"2-parameter-description",level:3},{value:"Key Features",id:"key-features",level:2},{value:"Important Notes",id:"important-notes",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"agentic-rag-implementation-in-autoagent",children:"Agentic RAG Implementation in AutoAgent"})}),"\n",(0,i.jsxs)(n.p,{children:["Agentic RAG (Retrieval-Augmented Generation) is an intelligent retrieval system that can decide whether and how to retrieve information from a knowledge base as needed. Traditional RAG methods (such as ",(0,i.jsx)(n.a,{href:"https://github.com/chonkie-ai/chonkie",children:"chunkRAG"}),", ",(0,i.jsx)(n.a,{href:"https://github.com/HKUDS/MiniRAG",children:"MiniRAG"}),", ",(0,i.jsx)(n.a,{href:"https://github.com/HKUDS/LightRAG",children:"LightRAG"}),", and ",(0,i.jsx)(n.a,{href:"https://github.com/microsoft/graphrag",children:"GraphRAG"}),") have limitations as they rely on predefined workflows and struggle to determine if they have acquired sufficient knowledge to answer questions. To make the RAG process more intelligent, we introduce Agentic RAG powered by ",(0,i.jsx)(n.a,{href:"https://github.com/HKUDS/AutoAgent",children:"AutoAgent"}),", implementing intelligent storage, retrieval, and response."]}),"\n",(0,i.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,i.jsx)(n.h3,{id:"1-required-imports",children:"1. Required Imports"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from constant import DOCKER_WORKPLACE_NAME\nfrom autoagent.environment.docker_container import init_container\nfrom autoagent.io_utils import read_yaml_file, get_md5_hash_bytext\nfrom autoagent.agents import get_rag_agent\nfrom autoagent.core import AutoAgent\nfrom autoagent.environment.docker_env import DockerEnv, DockerConfig, with_env\nimport argparse\nimport asyncio\nimport csv\nfrom tqdm import trange\nimport os\nimport json\nimport time\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-environment-configuration",children:"2. Environment Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def get_env(container_name: str = 'gaia_test', \n            model: str = 'gpt-4o-mini-2024-07-18',\n            git_clone: bool = False, \n            setup_package: str = 'lite_pkgs'):\n    workplace_name = DOCKER_WORKPLACE_NAME\n    docker_config = DockerConfig(\n        container_name=container_name,\n        workplace_name=workplace_name,\n        communication_port=12345,\n        conda_path='/home/user/micromamba'\n    )\n    docker_env = DockerEnv(docker_config)\n    return docker_env\n"})}),"\n",(0,i.jsx)(n.p,{children:"The system runs in a Docker container, providing an isolated environment with the following main configurations:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Container name"}),"\n",(0,i.jsx)(n.li,{children:"Working directory"}),"\n",(0,i.jsx)(n.li,{children:"Communication port"}),"\n",(0,i.jsx)(n.li,{children:"Conda environment path"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-rag-agent-setup",children:"3. RAG Agent Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"async def main(container_name: str = 'gaia_test', model: str = 'gpt-4o-mini-2024-07-18', git_clone: bool = False, setup_package: str = 'lite_pkgs', test_pull_name: str = 'test_pull_1010', debug: bool = True, task_instructions: str = None):\n    workplace_name = DOCKER_WORKPLACE_NAME\n    # Docker environment is optional\n    # docker_env = get_env(container_name, model, git_clone, setup_package, test_pull_name, debug)\n    # docker_env.init_container()\n\n    task_instructions = \"YOUR TASK\"\n\n    rag_agent = get_rag_agent(model)#, rag_env=docker_env)\n    mc = AutoAgent()\n"})}),"\n",(0,i.jsx)(n.p,{children:"The system uses the AutoAgent framework to manage RAG agents, with key features including:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Asynchronous operation support"}),"\n",(0,i.jsx)(n.li,{children:"Configurable language models"}),"\n",(0,i.jsx)(n.li,{children:"Flexible message handling mechanism"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-query-processing-flow",children:"4. Query Processing Flow"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'context_variables = {\n    "working_dir": DOCKER_WORKPLACE_NAME,\n    "user_query": task_instructions\n}\nmessages = [{"role": "user", "content": task_instructions}]\nresponse = await mc.run_async(\n    agent=codeact_agent, \n    messages=messages,\n    max_turns=10, \n    context_variables=context_variables, \n    debug=debug\n)\n'})}),"\n",(0,i.jsx)(n.p,{children:"Query processing includes the following steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Setting context variables"}),"\n",(0,i.jsx)(n.li,{children:"Building message format"}),"\n",(0,i.jsx)(n.li,{children:"Asynchronous agent execution"}),"\n",(0,i.jsx)(n.li,{children:"Controlling maximum conversation turns"}),"\n",(0,i.jsx)(n.li,{children:"Debug mode support"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,i.jsxs)(n.p,{children:["We put a basic usage example in ",(0,i.jsx)(n.a,{href:"https://github.com/HKUDS/AutoAgent/tree/main/evaluation/multihoprag",children:(0,i.jsx)(n.code,{children:"AutoAgent/evaluation/multihoprag"})}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"1-basic-usage",children:"1. Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'current_dir=$(dirname "$(readlink -f "$0")")\n\ncd $current_dir\ncd ../\nexport DOCKER_WORKPLACE_NAME=workplace_rag\nexport EVAL_MODE=True\nexport DEBUG=True\nexport BASE_IMAGES=tjbtech1/gaia-bookworm:v2\nexport COMPLETION_MODEL=claude-3-5-sonnet-20241022\n\npython run_rag.py --model gpt-4o-mini-2024-07-18 --container_name gaia_test\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-parameter-description",children:"2. Parameter Description"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--container_name"}),": Docker container name"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--model"}),": Language model to use"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--git_clone"}),": Whether to clone code"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--setup_package"}),": Package type to install"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"--debug"}),": Whether to enable debug mode"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Asynchronous Processing"}),": Using ",(0,i.jsx)(n.code,{children:"asyncio"})," for improved processing efficiency"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Containerized Deployment"}),": Using Docker for environment consistency"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flexible Configuration"}),": Support for various models and parameter configurations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Batch Processing"}),": Support for batch query processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Result Tracking"}),": Saving queries and responses for evaluation and analysis"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"important-notes",children:"Important Notes"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Ensure proper Docker environment configuration"}),"\n",(0,i.jsx)(n.li,{children:"Check model access permissions and configurations"}),"\n",(0,i.jsx)(n.li,{children:"Set appropriate maximum conversation turns"}),"\n",(0,i.jsx)(n.li,{children:"Maintain data format consistency"}),"\n",(0,i.jsx)(n.li,{children:"Regular backup of result files"}),"\n"]})]})}function g(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);